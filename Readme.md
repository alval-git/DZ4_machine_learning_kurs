
В рамках данной работы решалась задача  классификации для предсказания выживания пассажиров Титаника.
Для решения проблемы дисбаланса классов были применены шесть различных стратегий перевзвешивания. Undersampling предполагал случайное удаление примеров мажоритарного класса до достижения баланса. Oversampling использовал случайное дублирование примеров миноритарного класса. SMOTE и ADASYN представляли более сложные подходы с синтетическим созданием новых примеров на основе пространства признаков существующих данных. SMOTEENN комбинировал метод SMOTE с последующей очисткой данных от шумных примеров. Также была рассмотрена стратегия без применения балансировки для сравнения эффективности.

Было протестировано пять алгоритмов машинного обучения: Random Forest, Logistic Regression, AdaBoost, LightGBM и CatBoost. Для каждой модели проводилась оптимизация гиперпараметров с использованием RandomizedSearchCV с кросс-валидацией. Основной метрикой оценки являлся F1-Score, как наиболее сбалансированный показатель для задач с неравномерным распределением классов.

Наилучшие результаты по метрике F1-Score были достигнуты при использовании методов Undersampling и Oversampling, которые показали идентичное значение 0.7785. В случае Undersampling лучшей моделью оказался CatBoost, тогда как при Oversampling максимальную эффективность продемонстрировал AdaBoost. Важно отметить, что работа без балансировки данных при использовании CatBoost показала достойные результаты по ROC-AUC (0.8550) и Accuracy (0.8212), что свидетельствует о том, что современные алгоритмы машинного обучения способны в определенной степени справляться с дисбалансом классов самостоятельно.
CatBoost проявил себя как наиболее стабильная и эффективная модель, показывая высокие результаты с различными методами балансировки, поэтому лучшей моделью я выберу CatBoost